{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80da4387-433d-4c1a-83f3-bbcd09cde7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55296673-20cc-4a30-bfb8-392d5d858713",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /opt/ml/input/data/sample/ https://drive.google.com/u/0/uc?id=1EjSfLv-eb-nWAW-kZuJOyWQFOy0uY1aE&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40a72869-a289-45ae-b88a-5f0f5dd4295b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3873e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(size=(4,), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23ce8d1a-8b1d-4112-87a5-033451c7f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3873e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(size=(3, 4), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2901e589-3d7f-4b05-832b-3e1f46f607c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3873e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(size=(2, 3, 4), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e4d8c2e-69be-43c7-9cfd-9901f656a785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0333, 0.0333, 0.0333, 0.0333],\n",
       "         [0.0333, 0.0333, 0.0333, 0.0333],\n",
       "         [0.0333, 0.0333, 0.0333, 0.0333]],\n",
       "\n",
       "        [[0.0333, 0.0333, 0.0333, 0.0333],\n",
       "         [0.0333, 0.0333, 0.0333, 0.0333],\n",
       "         [0.0333, 0.0333, 0.0333, 0.0333]]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(size=(2, 3, 4), device='cuda')\\\n",
    ".fill_(0.1 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a488d6d7-12bb-4f49-9698-56039f11b4e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_scatter_",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f690ee470efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_scatter_"
     ]
    }
   ],
   "source": [
    "torch.empty(size=(2, 3, 4), device='cuda')\\\n",
    ".fill_(0.1 / 3)\\\n",
    ".scatter_(-1, torch.randint(1, 7, (4,)).data.unsqueeze(-1), torch.empty(size=(4,), device='cuda').fill_(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9813d649-8b1b-4044-ab4b-d0189a35a46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [6],\n",
       "        [5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1, 7, (4,)).data.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141ada1e-2b01-4eb1-ac57-01ebb4974a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Running SATRN on device cuda\n",
      "\n",
      "[+] System environments\n",
      " The number of gpus : 1\n",
      " The number of cpus : 8\n",
      " Memory Size : 83G\n",
      "\n",
      "[+] Data\n",
      " The number of train samples : 80000\n",
      " The number of validation samples : 20000\n",
      " The number of classes : 245\n",
      "\n",
      "[+] Network\n",
      " Type: SATRN\n",
      " Encoder parameters: 5875140\n",
      " Decoder parameters: 988917 \n",
      "\n",
      "teacher_forcing 0.5\n",
      "Traceback (most recent call last):                                              \n",
      "  File \"train.py\", line 475, in <module>\n",
      "    main(parser.config_file)\n",
      "  File \"train.py\", line 340, in main\n",
      "    train=True,\n",
      "  File \"train.py\", line 110, in run_epoch\n",
      "    loss = criterion(decoded_values, expected[:, 1:])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/ml/code/networks/SATRN.py\", line 63, in forward\n",
      "    targets = LabelSmoothingCrossEntropy._smooth_one_hot(targets, self.num_classes, self.smoothing, self.ignore_index) # inputs.size(-1)\n",
      "  File \"/opt/ml/code/networks/SATRN.py\", line 46, in _smooth_one_hot\n",
      "    .scatter_(-1, targets.data.unsqueeze(1), 1. - smoothing) # dim=-1로 수정\n",
      "RuntimeError: invalid argument 4: Index tensor must have same size as output tensor apart from the specified dimension at /pytorch/aten/src/THC/generic/THCTensorScatterGather.cu:324\n"
     ]
    }
   ],
   "source": [
    "!sh satrn12.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581af0e-6555-489b-bfdb-ca5041a701fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e9be5-7275-478f-8658-4cfb4bc268f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelSmoothingLoss(nn.Module):\n",
    "#     \"\"\"\n",
    "#     With label smoothing,\n",
    "#     KL-divergence between q_{smoothed ground truth prob.}(w)\n",
    "#     and p_{prob. computed by model}(w) is minimized.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, label_smoothing, tgt_vocab_size, ignore_index=-100):\n",
    "#         assert 0.0 < label_smoothing <= 1.0\n",
    "#         self.ignore_index = ignore_index\n",
    "#         super(LabelSmoothingLoss, self).__init__()\n",
    "\n",
    "#         smoothing_value = label_smoothing / (tgt_vocab_size - 2)\n",
    "#         one_hot = torch.full((tgt_vocab_size,), smoothing_value) \n",
    "#         one_hot[self.ignore_index] = 0\n",
    "#         self.register_buffer('one_hot', one_hot.unsqueeze(0))\n",
    "\n",
    "#         self.confidence = 1.0 - label_smoothing\n",
    "\n",
    "#     def forward(self, output, target):\n",
    "#         \"\"\"\n",
    "#         output (FloatTensor): batch_size x n_classes\n",
    "#         target (LongTensor): batch_size\n",
    "#         \"\"\"\n",
    "#         model_prob = self.one_hot.repeat(target.size(0), 1)\n",
    "#         model_prob.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "#         model_prob.masked_fill_((target == self.ignore_index).unsqueeze(1), 0)\n",
    "\n",
    "#         return F.kl_div(output, model_prob, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a5ed08-d49a-4d0a-806e-f6abf19f38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa399d-dbe8-4cc3-9042-595acf64c515",
   "metadata": {},
   "source": [
    "# 단일 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b089196-9373-4a42-b8a4-d3a9c03494f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용될 변수 선언\n",
    "smoothing_value = 0.1\n",
    "vocab_size = 3\n",
    "sentence_size = 5\n",
    "ignore_index=0\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd674d4-1b6b-4339-a69d-b09a6746d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.full((tgt_vocab_size,), smoothing_value / (tgt_vocab_size - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d625394-8954-4f21-9807-58d9c60944e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor,\n",
       " tensor([[[0.3275, 0.6315, 0.4642, 0.7919, 0.0574],\n",
       "          [0.9240, 0.0242, 0.1589, 0.1785, 0.8554],\n",
       "          [0.5115, 0.9508, 0.7066, 0.3282, 0.9478]],\n",
       " \n",
       "         [[0.1753, 0.7012, 0.1265, 0.6870, 0.9951],\n",
       "          [0.4266, 0.8570, 0.1130, 0.0105, 0.3365],\n",
       "          [0.8641, 0.5406, 0.6147, 0.8150, 0.9605]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의로 설정한 target\n",
    "target = torch.rand(size=(batch_size, vocab_size, sentence_size))\n",
    "type(target), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fb5f88-60d2-4e9d-aac4-1c83f166314c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5bdab9a0c682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msmoothing_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "# one_hot vector에 smoothing 적용\n",
    "one_hot = torch.full((tgt_vocab_size,), smoothing_value/(7-2)) # size 만큼 smoothing_value로 채우기\n",
    "one_hot[[0,1,2]] = 0.0\n",
    "one_hot = one_hot.repeat(batch_size, 1)\\\n",
    "                .scatter(1, target.unsqueeze(1), 1 - smoothing_value)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2327232e-f524-47db-96f1-67c2b30e8a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 class는 사용X\n",
    "one_hot[ignore_index] = 0.0\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "51868af0-9413-43b0-a951-2d46c060547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size만큼 늘려주기\n",
    "one_hot_smoothing = one_hot.repeat(batch_size, 1) # size: (*origin) => (4, *origin)\n",
    "one_hot_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "12467c1d-09f5-455a-a7bf-aeb7f221a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaa846e-cac0-418a-ad6f-c59733aca3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, tensor([6, 4, 3, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의로 설정한 target\n",
    "target = torch.randint(1, 7, (batch_size,))\n",
    "type(target), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c951e6eb-ea3f-4f12-9156-8d2dd9061a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7]), torch.Size([4]), torch.Size([4, 1]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing.shape, target.shape, target.unsqueeze(-1).shape, target.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d7039be8-eb03-45f1-bcb9-dfdf7727c8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0000, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0000, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0000, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_hot_smoothing 완성\n",
    "one_hot_smoothing = one_hot_smoothing.scatter(1, target.unsqueeze(1), 1 - smoothing_value) # scatter에서 inplace=True 옵션\n",
    "one_hot_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "00cb3b82-79fc-42c5-a119-24d3c6eb584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "88be2c3a-02d6-44cf-aafd-a7ed970d5b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0350, 0.1968, 0.1322, 0.4622, 0.0382, 0.0231, 0.5226],\n",
       "        [0.8962, 0.8766, 0.5369, 0.0406, 0.3827, 0.1069, 0.7799],\n",
       "        [0.8783, 0.7525, 0.5823, 0.6227, 0.3112, 0.1279, 0.0992],\n",
       "        [0.4562, 0.2876, 0.9744, 0.1390, 0.7229, 0.7142, 0.6335]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand((batch_size, tgt_vocab_size))\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "36aa36a8-5a85-4dcb-be89-a36d8554c1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1318, -1.9700, -2.0346, -1.7046, -2.1287, -2.1437, -1.6443],\n",
       "        [-1.6187, -1.6383, -1.9780, -2.4743, -2.1322, -2.4080, -1.7350],\n",
       "        [-1.5888, -1.7147, -1.8849, -1.8445, -2.1559, -2.3393, -2.3680],\n",
       "        [-2.0852, -2.2538, -1.5669, -2.4024, -1.8185, -1.8272, -1.9079]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm = F.log_softmax(input, -1)\n",
    "lsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "90b85f35-b816-4872-82ea-49a45cdd314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "34e05742-a035-4583-8066-6f7306fcc88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0088, 2.1560, 1.9011, 2.3914])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -(one_hot_smoothing2 * lsm).sum(-1)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a50358e6-7a3f-4b80-8936-2a9e5bf39b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.4572), tensor(2.1143))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum(), loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c5874d15-d2d0-442b-a177-af944157edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.1):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets: torch.Tensor, n_classes: int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "#             targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "#                                   device=targets.device) \\\n",
    "#                 .fill_(smoothing / (n_classes - 1)) \\\n",
    "#                 .scatter_(-1, targets.data.unsqueeze(-1), 1. - smoothing) # dim=-1로 수정\n",
    "            \n",
    "            targets = torch.full((tgt_vocab_size,), smoothing_value/(7-2)) # size 만큼 smoothing_value로 채우기\n",
    "            targets[[0,1,2]] = 0.0\n",
    "            targests = targets.repeat(batch_size, 1)\\\n",
    "                            .scatter(1, target.unsqueeze(1), 1 - smoothing_value)\n",
    "        return targets\n",
    "    \n",
    "            \n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = LabelSmoothingCrossEntropy._smooth_one_hot(targets, inputs.size(-1), self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "25dff597-e43c-405e-818d-730625ab0265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4013e-45,  0.0000e+00,  6.9868e-35,  3.0775e-41,  3.9236e-44,\n",
       "          3.0775e-41,  2.9446e-22],\n",
       "        [ 4.5766e-41,  2.8026e-45,  4.5766e-41,  2.8026e-45,  4.5766e-41,\n",
       "          1.4013e-45,  0.0000e+00],\n",
       "        [ 3.9236e-44,  0.0000e+00, -1.4419e+01,  4.5766e-41,  1.4013e-45,\n",
       "          4.5766e-41,  1.4013e-45],\n",
       "        [ 1.8470e+31,  1.4013e-45,  2.9427e-44,  3.5032e-44,  2.9427e-44,\n",
       "          6.9868e-35,  3.0775e-41]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing2 = torch.empty(size=(batch_size, tgt_vocab_size))\n",
    "one_hot_smoothing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "da5aa6a3-a7f2-402d-98ce-c41f01bb9ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing2.fill_(smoothing_value / (7 - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9d4b3e92-ab8e-4295-ba84-ae95dc53f386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200],\n",
       "        [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing2.scatter_(1, target.data.unsqueeze(1), 1. - smoothing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc7075d5-12f1-4434-9ed6-27afdb0bbf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4798, 0.7551, 0.9597, 0.0752, 0.7422, 0.7434, 0.2026],\n",
       "        [0.9297, 0.3580, 0.9226, 0.6550, 0.1149, 0.3633, 0.3856],\n",
       "        [0.1226, 0.6131, 0.6585, 0.8673, 0.9857, 0.9856, 0.1894],\n",
       "        [0.0175, 0.2836, 0.0773, 0.6193, 0.0162, 0.1845, 0.8570]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.rand((batch_size, tgt_vocab_size))\n",
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "814b141d-714c-4228-94b3-4ca92a1dbbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0744, -1.7991, -1.5945, -2.4790, -1.8119, -1.8108, -2.3516],\n",
       "        [-1.5909, -2.1626, -1.5979, -1.8655, -2.4057, -2.1573, -2.1350],\n",
       "        [-2.5061, -2.0156, -1.9703, -1.7614, -1.6431, -1.6432, -2.4394],\n",
       "        [-2.2709, -2.0047, -2.2110, -1.6690, -2.2721, -2.1038, -1.4314]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm = F.log_softmax(input2, -1)\n",
    "lsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4aba7f77-cae7-4c4f-9f52-12b543cab949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8617, 2.3953, 1.8296, 1.7480])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = -(one_hot_smoothing2 * lsm).sum(-1)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "163b6ab2-b161-473e-ba13-935f5fdaa741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.8346), tensor(1.9586))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2.sum(), loss2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d937f7e-42b3-4ab9-87ea-b89c4a181d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    ".empty(size=(배치사이즈, n_classes), device=targets.device) # Returns a tensor filled with uninitialized data\n",
    ".fill_(smoothing / (n_classes - 1)) # 스무싱값 채우기\n",
    ".scatter_(1, targets.data.unsqueeze(1), 1. - smoothing) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7b7e2057-a088-4c42-a7c7-3fe2cdeb1dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1479e-41,  0.0000e+00,  7.0625e-43,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  6.9919e-35],\n",
       "         [ 3.0775e-41,  1.4013e-45,  0.0000e+00,  6.9921e-35,  3.0775e-41,\n",
       "           1.4013e-45,  0.0000e+00],\n",
       "         [ 6.9919e-35,  3.0775e-41,  3.9236e-44,  3.0775e-41,  2.8718e-22,\n",
       "           4.5766e-41,  2.8026e-45],\n",
       "         [ 4.5766e-41,  2.8026e-45,  4.5766e-41,  1.4013e-45,  0.0000e+00,\n",
       "           3.9236e-44,  0.0000e+00],\n",
       "         [-1.4419e+01,  4.5766e-41,  1.4013e-45,  4.5766e-41,  1.4013e-45,\n",
       "           0.0000e+00,  1.4013e-45],\n",
       "         [ 2.9427e-44,  3.5032e-44,  2.9427e-44,  6.9919e-35,  3.0775e-41,\n",
       "          -2.0462e+06,  4.5766e-41],\n",
       "         [ 1.4013e-45,  4.5766e-41,  1.4013e-45,  2.9427e-44,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.4013e-45,  0.0000e+00,  6.9921e-35,  3.0775e-41,\n",
       "           4.2039e-45,  0.0000e+00],\n",
       "         [ 6.9920e-35,  3.0775e-41,  6.9920e-35,  3.0775e-41,  6.9921e-35,\n",
       "           3.0775e-41,  3.9236e-44],\n",
       "         [ 0.0000e+00,  3.8169e-22,  4.5766e-41,  1.4013e-45,  0.0000e+00,\n",
       "           6.9920e-35,  3.0775e-41]],\n",
       "\n",
       "        [[ 1.4013e-45,  5.4651e-44,  3.9236e-44,  3.0775e-41,  2.8403e-22,\n",
       "           4.5766e-41,  1.4013e-45],\n",
       "         [ 4.5766e-41,  1.4013e-45,  3.0774e-41,  1.4013e-45,  7.1466e-44,\n",
       "           3.9236e-44,  5.4651e-44],\n",
       "         [ 3.7235e-22,  4.5766e-41,  1.4013e-45,  4.5766e-41,  1.4013e-45,\n",
       "           2.6707e+17,  1.4013e-45],\n",
       "         [ 9.2486e-44,  4.2039e-44,  7.1466e-44,  6.9920e-35,  3.0775e-41,\n",
       "           1.4013e-45,  4.5766e-41],\n",
       "         [ 1.4013e-45,  0.0000e+00,  1.4013e-45,  5.4651e-44, -2.2608e+06,\n",
       "           4.5766e-41,  6.9921e-35],\n",
       "         [ 3.0775e-41,  2.2421e-44,  3.0775e-41,  6.9920e-35,  3.0775e-41,\n",
       "           6.9920e-35,  3.0775e-41],\n",
       "         [ 6.9920e-35,  3.0775e-41,  1.4013e-45,  2.9427e-44,  8.4078e-45,\n",
       "           3.0775e-41,  6.9919e-35],\n",
       "         [ 3.0775e-41,  6.9921e-35,  3.0775e-41,  6.9920e-35,  3.0775e-41,\n",
       "           6.9920e-35,  3.0775e-41],\n",
       "         [ 1.4013e-45,  2.9427e-44,  1.4013e-45,  0.0000e+00,  1.4013e-45,\n",
       "           3.0775e-41,  6.9919e-35],\n",
       "         [ 3.0775e-41,  0.0000e+00,  0.0000e+00,  1.4013e-45,  0.0000e+00,\n",
       "           1.4013e-45,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.4013e-45,  0.0000e+00,  3.9236e-44,  1.8963e+17,  2.8718e-22,\n",
       "           4.5766e-41,  1.4013e-45],\n",
       "         [ 4.5766e-41,  0.0000e+00,  0.0000e+00,  2.8026e-45,  0.0000e+00,\n",
       "           3.0829e-44,  0.0000e+00],\n",
       "         [ 6.9922e-35,  3.0775e-41,  1.1074e+30,  3.0774e-41,  4.2039e-45,\n",
       "           0.0000e+00,  2.8026e-45],\n",
       "         [ 0.0000e+00,  1.4013e-45,  0.0000e+00,  2.8026e-45,  0.0000e+00,\n",
       "           1.4013e-45,  6.3667e+16],\n",
       "         [ 6.9919e-35,  3.0775e-41,  1.2612e-44,  0.0000e+00,  2.9408e-22,\n",
       "           4.5766e-41,  1.1074e+30],\n",
       "         [ 3.0774e-41,  1.4013e-45,  0.0000e+00,  7.9811e-10,  8.9262e-10,\n",
       "           6.3667e+16,  1.6692e-07],\n",
       "         [ 2.7042e-27,  4.5766e-41,  1.4013e-45,  8.1714e+20,  9.4167e-43,\n",
       "           0.0000e+00,  4.2039e-45],\n",
       "         [ 0.0000e+00,  2.9408e-22,  4.5766e-41,  1.1074e+30,  3.0774e-41,\n",
       "           4.7987e+30,  2.7945e+32],\n",
       "         [ 8.1714e+20,  9.0480e-04,  4.3605e+27,  5.1723e+28,  2.7042e-27,\n",
       "           4.5766e-41,  1.4013e-45],\n",
       "         [ 1.1259e+24,  1.0426e-42,  0.0000e+00,  9.8091e-45,  0.0000e+00,\n",
       "           2.9408e-22,  4.5766e-41]],\n",
       "\n",
       "        [[ 1.1075e+30,  3.0774e-41,  0.0000e+00,  0.0000e+00,  4.2039e-45,\n",
       "           0.0000e+00,  2.8026e-45],\n",
       "         [ 0.0000e+00,  2.7042e-27,  4.5766e-41,  1.4013e-45,  1.8059e+28,\n",
       "           2.9408e-22,  4.5766e-41],\n",
       "         [ 2.9408e-22,  4.5766e-41,  2.9408e-22,  4.5766e-41,  2.9408e-22,\n",
       "           4.5766e-41,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.1435e-42,  0.0000e+00,  2.8026e-45,  0.0000e+00,\n",
       "           2.9408e-22,  4.5766e-41],\n",
       "         [ 1.1074e+30,  3.0774e-41,  5.3179e+22,  1.0525e+21,  5.6052e-45,\n",
       "           0.0000e+00,  2.8026e-45],\n",
       "         [ 0.0000e+00,  2.7042e-27,  4.5766e-41,  1.4013e-45,  6.1948e-04,\n",
       "           2.9408e-22,  4.5766e-41],\n",
       "         [ 2.9408e-22,  4.5766e-41,  2.9408e-22,  4.5766e-41,  2.9408e-22,\n",
       "           4.5766e-41,  2.9408e-22],\n",
       "         [ 4.5766e-41,  1.3004e-42,  0.0000e+00,  1.5414e-44,  0.0000e+00,\n",
       "           2.9408e-22,  4.5766e-41],\n",
       "         [ 1.1075e+30,  3.0774e-41,  1.4013e-45,  0.0000e+00,  4.2740e-43,\n",
       "           0.0000e+00, -1.6531e+06],\n",
       "         [ 4.5766e-41,  2.7042e-27,  4.5766e-41,  1.4013e-45,  4.5766e-41,\n",
       "           1.4574e-42,  0.0000e+00]]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing3 = torch.empty(size=(batch_size, sentence_size, tgt_vocab_size))\n",
    "one_hot_smoothing3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "92bb4e1a-a2de-454c-b7e1-514adfd1da3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]],\n",
       "\n",
       "        [[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]],\n",
       "\n",
       "        [[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]],\n",
       "\n",
       "        [[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing3.fill_(smoothing_value / (7 - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cddb4150-abed-487b-9a71-f66476b700a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 2, 2, 1, 3, 6, 5, 3, 1],\n",
       "        [2, 2, 3, 3, 4, 3, 5, 2, 2, 5],\n",
       "        [5, 6, 4, 3, 2, 4, 1, 1, 4, 5],\n",
       "        [6, 2, 6, 5, 4, 2, 5, 6, 3, 4]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의로 설정한 target2\n",
    "target2 = torch.randint(1, 7, (batch_size, sentence_size))\n",
    "target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267a1a2b-ff86-4cd5-8480-933f38ece0b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7dcc3bbe9ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'target2' is not defined"
     ]
    }
   ],
   "source": [
    "target2.data.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "54778cd2-a5c6-44ba-b250-b068ed99e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 7])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c65960a7-8bb8-4b34-b2d0-d42a04e7f73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200]],\n",
       "\n",
       "        [[0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200]],\n",
       "\n",
       "        [[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200],\n",
       "         [0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200]],\n",
       "\n",
       "        [[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.9000],\n",
       "         [0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200, 0.0200],\n",
       "         [0.0200, 0.0200, 0.0200, 0.0200, 0.9000, 0.0200, 0.0200]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_smoothing3.scatter_(-1, target2.data.unsqueeze(-1), 1. - smoothing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4c65d0d7-0f09-4512-9c18-e7f40707c6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5487, 0.9717, 0.2875, 0.6378, 0.3798, 0.6251, 0.0547],\n",
       "         [0.7149, 0.6334, 0.2612, 0.4684, 0.4854, 0.8011, 0.4887],\n",
       "         [0.0387, 0.7028, 0.3883, 0.4006, 0.0918, 0.9622, 0.0714],\n",
       "         [0.2497, 0.6634, 0.4704, 0.9193, 0.6834, 0.4758, 0.1633],\n",
       "         [0.8740, 0.2523, 0.7250, 0.8226, 0.8815, 0.0855, 0.6467],\n",
       "         [0.1503, 0.1988, 0.8766, 0.7593, 0.5198, 0.0115, 0.2395],\n",
       "         [0.4910, 0.6331, 0.8914, 0.3337, 0.6730, 0.4047, 0.5865],\n",
       "         [0.8565, 0.9654, 0.2573, 0.3034, 0.0878, 0.3548, 0.9704],\n",
       "         [0.4272, 0.9506, 0.5214, 0.0863, 0.4009, 0.6624, 0.9607],\n",
       "         [0.7273, 0.2726, 0.2690, 0.9050, 0.8579, 0.6589, 0.1345]],\n",
       "\n",
       "        [[0.8537, 0.2266, 0.4101, 0.7861, 0.6663, 0.6928, 0.6434],\n",
       "         [0.4854, 0.0454, 0.5276, 0.5244, 0.9286, 0.8998, 0.8000],\n",
       "         [0.2681, 0.8655, 0.3118, 0.9855, 0.9043, 0.3197, 0.2840],\n",
       "         [0.4315, 0.2057, 0.1980, 0.8653, 0.9962, 0.5771, 0.2604],\n",
       "         [0.6168, 0.0961, 0.2448, 0.3927, 0.6982, 0.5850, 0.8828],\n",
       "         [0.7299, 0.8172, 0.3125, 0.9767, 0.7032, 0.8733, 0.6880],\n",
       "         [0.5082, 0.0962, 0.5369, 0.1083, 0.3370, 0.1988, 0.4664],\n",
       "         [0.7807, 0.6723, 0.2746, 0.5480, 0.7739, 0.1275, 0.7598],\n",
       "         [0.0951, 0.0554, 0.0617, 0.1037, 0.5995, 0.9321, 0.5705],\n",
       "         [0.5215, 0.8364, 0.9042, 0.3817, 0.5454, 0.5838, 0.2671]],\n",
       "\n",
       "        [[0.6749, 0.3313, 0.6335, 0.3202, 0.1677, 0.3987, 0.1432],\n",
       "         [0.8306, 0.6804, 0.8127, 0.4645, 0.2544, 0.1486, 0.8004],\n",
       "         [0.0974, 0.9422, 0.8819, 0.0863, 0.4628, 0.8478, 0.2308],\n",
       "         [0.2464, 0.8377, 0.2388, 0.6488, 0.6247, 0.4673, 0.2810],\n",
       "         [0.3618, 0.0410, 0.5322, 0.1689, 0.2540, 0.5430, 0.0040],\n",
       "         [0.9025, 0.4093, 0.1596, 0.9882, 0.1060, 0.1824, 0.2025],\n",
       "         [0.8431, 0.8023, 0.3784, 0.3626, 0.3980, 0.8368, 0.2980],\n",
       "         [0.2746, 0.3734, 0.2966, 0.5183, 0.7172, 0.2637, 0.1926],\n",
       "         [0.5544, 0.5085, 0.8275, 0.5775, 0.2627, 0.3971, 0.1604],\n",
       "         [0.3271, 0.4030, 0.1607, 0.6392, 0.8504, 0.0185, 0.9141]],\n",
       "\n",
       "        [[0.7535, 0.3305, 0.7922, 0.3247, 0.3769, 0.7131, 0.3972],\n",
       "         [0.0481, 0.7961, 0.5097, 0.5946, 0.5008, 0.4401, 0.2980],\n",
       "         [0.9328, 0.8166, 0.0387, 0.5048, 0.3674, 0.4222, 0.7421],\n",
       "         [0.8276, 0.0864, 0.6314, 0.6368, 0.0464, 0.6635, 0.3228],\n",
       "         [0.8906, 0.6572, 0.9560, 0.2006, 0.9929, 0.0967, 0.2682],\n",
       "         [0.3854, 0.2497, 0.9148, 0.8426, 0.5110, 0.0463, 0.0737],\n",
       "         [0.4117, 0.0775, 0.0805, 0.9259, 0.1807, 0.3047, 0.0141],\n",
       "         [0.0224, 0.1397, 0.3786, 0.8672, 0.4816, 0.2970, 0.1125],\n",
       "         [0.4319, 0.9889, 0.0875, 0.6661, 0.9312, 0.6131, 0.6336],\n",
       "         [0.4871, 0.9178, 0.0844, 0.5751, 0.4443, 0.2477, 0.2601]]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input3 = torch.rand((batch_size, sentence_size, tgt_vocab_size))\n",
    "input3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "81998213-411c-481d-8bac-df234850e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9350, -1.5120, -2.1962, -1.8459, -2.1039, -1.8586, -2.4290],\n",
       "         [-1.7953, -1.8768, -2.2489, -2.0418, -2.0247, -1.7091, -2.0215],\n",
       "         [-2.3421, -1.6780, -1.9925, -1.9802, -2.2890, -1.4187, -2.3094],\n",
       "         [-2.2435, -1.8298, -2.0229, -1.5739, -1.8099, -2.0175, -2.3300],\n",
       "         [-1.7240, -2.3458, -1.8731, -1.7754, -1.7166, -2.5125, -1.9514],\n",
       "         [-2.2371, -2.1886, -1.5108, -1.6281, -1.8677, -2.3760, -2.1479],\n",
       "         [-2.0434, -1.9013, -1.6430, -2.2007, -1.8614, -2.1297, -1.9479],\n",
       "         [-1.6918, -1.5829, -2.2910, -2.2449, -2.4605, -2.1935, -1.5779],\n",
       "         [-2.1332, -1.6098, -2.0390, -2.4741, -2.1595, -1.8980, -1.5997],\n",
       "         [-1.8063, -2.2610, -2.2646, -1.6285, -1.6756, -1.8747, -2.3991]],\n",
       "\n",
       "        [[-1.7230, -2.3501, -2.1666, -1.7906, -1.9104, -1.8839, -1.9333],\n",
       "         [-2.1002, -2.5401, -2.0580, -2.0612, -1.6570, -1.6858, -1.7856],\n",
       "         [-2.2894, -1.6920, -2.2458, -1.5720, -1.6532, -2.2379, -2.2735],\n",
       "         [-2.0658, -2.2916, -2.2992, -1.6320, -1.5010, -1.9201, -2.2368],\n",
       "         [-1.8627, -2.3834, -2.2347, -2.0867, -1.7813, -1.8945, -1.5967],\n",
       "         [-1.9625, -1.8752, -2.3798, -1.7157, -1.9892, -1.8190, -2.0043],\n",
       "         [-1.7745, -2.1865, -1.7458, -2.1744, -1.9457, -2.0839, -1.8163],\n",
       "         [-1.7554, -1.8637, -2.2614, -1.9880, -1.7622, -2.4085, -1.7762],\n",
       "         [-2.2524, -2.2922, -2.2859, -2.2438, -1.7481, -1.4154, -1.7770],\n",
       "         [-2.0242, -1.7093, -1.6415, -2.1639, -2.0003, -1.9618, -2.2785]],\n",
       "\n",
       "        [[-1.6711, -2.0148, -1.7126, -2.0259, -2.1784, -1.9474, -2.2029],\n",
       "         [-1.7181, -1.8684, -1.7361, -2.0842, -2.2943, -2.4001, -1.7483],\n",
       "         [-2.4168, -1.5719, -1.6323, -2.4278, -2.0513, -1.6664, -2.2834],\n",
       "         [-2.2012, -1.6099, -2.2089, -1.7989, -1.8229, -1.9804, -2.1667],\n",
       "         [-1.8766, -2.1974, -1.7063, -2.0696, -1.9844, -1.6955, -2.2345],\n",
       "         [-1.5282, -2.0214, -2.2711, -1.4425, -2.3248, -2.2484, -2.2282],\n",
       "         [-1.6903, -1.7311, -2.1550, -2.1708, -2.1354, -1.6966, -2.2354],\n",
       "         [-2.0629, -1.9642, -2.0409, -1.8193, -1.6204, -2.0739, -2.1450],\n",
       "         [-1.8823, -1.9281, -1.6092, -1.8592, -2.1739, -2.0396, -2.2763],\n",
       "         [-2.1416, -2.0657, -2.3079, -1.8294, -1.6182, -2.4501, -1.5546]],\n",
       "\n",
       "        [[-1.7392, -2.1622, -1.7005, -2.1680, -2.1158, -1.7796, -2.0955],\n",
       "         [-2.3761, -1.6281, -1.9145, -1.8296, -1.9234, -1.9841, -2.1262],\n",
       "         [-1.5985, -1.7147, -2.4926, -2.0265, -2.1640, -2.1092, -1.7892],\n",
       "         [-1.6164, -2.3576, -1.8126, -1.8072, -2.3977, -1.7805, -2.1212],\n",
       "         [-1.6969, -1.9304, -1.6316, -2.3870, -1.5947, -2.4909, -2.3194],\n",
       "         [-2.0450, -2.1807, -1.5156, -1.5878, -1.9194, -2.3841, -2.3567],\n",
       "         [-1.8673, -2.2015, -2.1985, -1.3530, -2.0982, -1.9743, -2.2649],\n",
       "         [-2.2897, -2.1725, -1.9336, -1.4450, -1.8306, -2.0152, -2.1997],\n",
       "         [-2.1734, -1.6164, -2.5177, -1.9391, -1.6741, -1.9921, -1.9716],\n",
       "         [-1.9229, -1.4922, -2.3256, -1.8349, -1.9658, -2.1623, -2.1500]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm3 = F.log_softmax(input3, -1)\n",
    "lsm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "26ba03e0-5b10-4d3b-ac22-dc1fa49033b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9020, 2.0532, 2.0336, 2.0567, 2.3423, 1.7119, 1.9887, 2.2111, 2.4555,\n",
       "         2.2679],\n",
       "        [2.1818, 2.0888, 1.6627, 1.7151, 1.8443, 1.7847, 2.1084, 2.2663, 2.2919,\n",
       "         2.0020],\n",
       "        [1.9888, 1.8155, 2.0862, 1.8588, 1.7768, 2.3271, 1.7996, 2.0030, 2.1884,\n",
       "         2.4355],\n",
       "        [2.1193, 1.9604, 1.8524, 1.8447, 1.6844, 1.6135, 2.0165, 2.2135, 1.9841,\n",
       "         2.0070]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss3 = -(one_hot_smoothing3 * lsm3).sum(-1)\n",
    "loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ca9d3f49-bd10-4bda-a1ee-39ddf00b3611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(80.5441), tensor(2.0136))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss3.sum(), loss3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b7b0f8-8885-445f-8599-815f03d9fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 24, in <module>\n",
      "    from utils import get_network, get_optimizer\n",
      "  File \"/opt/ml/code/utils.py\", line 4, in <module>\n",
      "    from networks.SATRN import SATRN\n",
      "  File \"/opt/ml/code/networks/SATRN.py\", line 665\n",
      "    num_classes=len(train_dataset.id_to_token)\n",
      "               ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!sh satrn12.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
